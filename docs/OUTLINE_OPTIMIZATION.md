# 百万巨著大纲优化系统

## 概述

针对百万巨著（12卷+）的创作，我们实现了全新的**分层大纲 + 智能压缩 + 一致性索引**优化系统，解决了以下核心问题：

- ✅ **全书逻辑一致性**：避免不同卷之间的剧情冲突、角色矛盾
- ✅ **Token大幅节约**：节约60%+的API调用成本
- ✅ **卷边界清晰**：自动约束每卷的内容范围，不越界、不重复
- ✅ **全局视角**：AI在生成时能看到全书布局，避免伏笔丢失

---

## 核心功能

### 1. 卷核心要点提取

每卷自动提取3-5个核心要点（关键事件/转折），用于：
- 快速了解全书结构
- 生成新卷时参考其他卷的核心内容
- 避免重复已发生的关键事件

**使用方法**：
1. 在大纲管理页面，点击右上角"智能优化"按钮
2. 系统会为所有卷自动提取核心要点（约500 tokens/卷）
3. 提取完成后，核心要点会保存到数据库

**示例**：
```
第1卷《修行启程》核心要点：
- 主角觉醒雷系异能
- 击败学院导师成为新生第一
- 发现家族秘密

第2卷《秘境探险》核心要点：
- 进入远古秘境获得传承
- 结识红颜知己林雪
- 异能突破至A级
```

### 2. 智能上下文压缩

**原理**：
- **世界观压缩**：从800字压缩到200字核心规则（节约75%）
- **角色档案压缩**：只传递活跃角色和关键关系（节约70%）
- **全书索引**：用400字的卷索引替代2400字的完整上下文（节约83%）

**压缩前** (约4000 tokens)：
```
世界观设定：800字
角色档案：1000字（5-8个角色）
上一卷信息：500字
下一卷信息：300字
其他上下文：400字
```

**压缩后** (约1500 tokens)：
```
世界观核心规则：200字
活跃角色：200字（2-3个）
全书卷索引：400字（12卷×30字）
相邻卷要点：200字
其他上下文：500字
```

**节约效果**：约62.5%！

**使用方法**：
- 在生成章节时，"批量生成"模式下会看到"智能压缩"选项
- 默认启用（强烈推荐）
- 可以禁用以使用完整上下文（不推荐，token消耗很高）

### 3. 全书结构索引

生成章节时，AI会收到一个全书的卷索引：

```
【📚 全书结构索引】（12卷的核心要点，快速了解全书布局）
第1卷《修行启程》: 主角觉醒雷系异能、击败学院导师、发现家族秘密
第2卷《秘境探险》: 进入秘境获得传承、结识林雪、突破A级
第3卷《血魔宗之战》: 对抗血魔宗、林雪被掳走、主角突破S级
...
第12卷《终极对决》: 决战魔帝、拯救世界、封神
```

AI看到这个索引后：
- 了解当前卷在全书中的位置
- 知道哪些内容已经完成（前面的卷）
- 知道哪些内容属于未来（后面的卷）
- 确保不越界、不重复、不冲突

### 4. 卷边界约束增强

**三重约束机制**：

1. **上一卷已完成约束**：
   ```
   【⛔ 上一卷已完成内容】（第2卷，已完成，不可重复）
   第2卷：主角在秘境中获得传承，实力突破...

   🚫 严格禁止：
   - 不得重复上一卷已完成的剧情、冲突、场景
   - 上一卷的核心事件已经结束，本卷必须开启新的故事线
   ```

2. **下一卷预告约束**：
   ```
   【⛔ 下一卷内容预告】（第4卷，属于未来，不可提前写）
   第4卷：主角将挑战宗门大比，对战天才弟子...

   🚫 严格禁止：
   - 不得提前写下一卷的内容
   - 下一卷的关键事件、冲突、转折不能在本卷出现
   ```

3. **当前卷任务明确**：
   ```
   【✅ 当前卷任务】（第3卷，这是你要生成的）
   - 只关注本卷的剧情和冲突
   - 不重复上一卷，不提前写下一卷
   - 本卷的边界：从第81章到第120章
   ```

---

## 数据结构扩展

### Volume 类型增强

```typescript
export interface Volume {
  id: string
  projectId: string
  title: string
  summary: string
  order: number

  // 新增：核心要点（3-5个关键事件/转折）
  keyPoints?: string[]
  // 例如：["主角突破至金丹期", "击败血魔宗", "林雪牺牲"]

  // 新增：简要章节框架（可选，用于两阶段生成）
  briefChapters?: Array<{
    chapterNumber: number
    briefOutline: string  // 20-30字的简要大纲
  }>

  createdAt: string
  updatedAt: string
}
```

### 数据库 Schema 更新

```sql
ALTER TABLE volumes ADD COLUMN key_points TEXT DEFAULT '[]';
ALTER TABLE volumes ADD COLUMN brief_chapters TEXT DEFAULT '[]';
```

---

## 新增文件

### 1. `src/services/outline-optimizer.ts`

核心优化服务，包含：

- `compressWorldSetting()` - 压缩世界观设定
- `compressCharacters()` - 压缩角色档案
- `buildVolumeIndex()` - 构建全书卷索引
- `extractVolumeKeyPoints()` - 提取单卷核心要点
- `extractAllVolumeKeyPoints()` - 批量提取所有卷
- `buildCompressedContext()` - 构建压缩后的上下文
- `validateOutlineConsistency()` - 验证大纲一致性
- `calculateCompressionStats()` - 计算压缩统计

---

## 使用流程

### 推荐工作流（百万巨著）

1. **创建项目，生成12卷框架**
   - 使用"全自动创作"生成世界观、角色、12卷摘要

2. **提取所有卷的核心要点**
   - 在大纲管理页面，点击"智能优化"
   - 系统自动为12卷提取核心要点
   - 预计消耗：12卷 × 500 tokens = 6,000 tokens（一次性）

3. **按卷生成详细章节大纲**
   - 点击某一卷的"生成章节"按钮
   - 选择"批量生成"模式
   - **启用"智能压缩"**（默认已启用）
   - 设置章节数量（推荐40章）
   - 点击生成

4. **享受优化效果**
   - 每卷生成约消耗1,500 tokens（压缩后）
   - 12卷总计：18,000 tokens
   - 相比未优化：48,000 tokens
   - **节约：30,000 tokens (62.5%)**

### Token消耗对比

| 项目 | 未优化 | 优化后 | 节约 |
|-----|--------|--------|------|
| 单卷生成 | 4,000 tokens | 1,500 tokens | 62.5% |
| 12卷总计 | 48,000 tokens | 18,000 tokens | 62.5% |
| 提取要点（一次性） | - | 6,000 tokens | - |
| **总计** | **48,000 tokens** | **24,000 tokens** | **50%** |

即使加上提取要点的一次性消耗，整体仍然节约50%的token！

---

## 技术细节

### 压缩算法

1. **世界观压缩**：
   - 关键词匹配：`['等级', '境界', '修炼', '力量', '体系', '规则']`
   - 提取包含关键词的行
   - 限制总长度在200-250字

2. **角色压缩**：
   - 只保留`status === 'active'`的角色
   - 限制数量为2-3个
   - 只包含：名字、身份、主要关系

3. **卷索引构建**：
   - 每卷一行：`第X卷《标题》: 核心要点1、要点2、要点3`
   - 如果没有核心要点，使用摘要前50字
   - 总长度约400字（12卷）

### 智能压缩开关

在`generateVolumeChapters()`函数中：

```typescript
export async function generateVolumeChapters(
  // ...其他参数
  useCompression: boolean = true,  // 默认启用压缩
  allVolumes?: Volume[]           // 需要提供全部卷信息
): Promise<...> {
  if (useCompression && allVolumes && allVolumes.length > 0) {
    // 使用压缩上下文
    const compressed = buildCompressedContext({...})
    // 替换原始上下文
  } else {
    // 使用完整上下文
  }
}
```

---

## 一致性验证（预留功能）

`validateOutlineConsistency()` 函数可以检测：

1. **使用已故角色**：
   - 检测是否在新大纲中使用了已故角色
   - 提示：`使用了已故角色"XXX"（死于第X章）`

2. **提前使用下一卷内容**：
   - 检测是否涉及下一卷的关键要点
   - 提示：`可能涉及下一卷内容"XXX"，建议检查`

3. **重复上一卷内容**：
   - 检测是否重复上一卷的关键要点
   - 提示：`可能重复上一卷内容"XXX"，建议检查`

（此功能目前未在UI中集成，可在未来版本添加）

---

## 常见问题

### Q1: 必须先提取核心要点吗？

**A**: 不是必须的，但强烈推荐。

- 如果没有提取，系统会使用卷摘要（summary）的前50字作为替代
- 有核心要点的效果更好，因为更精准、更简洁

### Q2: 逐章生成模式支持压缩吗？

**A**: 逐章模式自带压缩机制，不需要额外的智能压缩。

- 逐章模式每章独立生成，天然token少
- 智能压缩主要用于批量模式

### Q3: 禁用压缩有什么影响？

**A**:
- Token消耗增加约2.5倍（1,500 → 4,000）
- 上下文更完整，但AI可能关注太多细节反而影响生成质量
- 不推荐禁用，除非你有特殊需求

### Q4: 可以重新提取核心要点吗？

**A**: 可以，随时点击"智能优化"按钮重新提取。

- 会覆盖现有的核心要点
- 适用于卷摘要修改后

### Q5: 12卷以下的项目需要优化吗？

**A**:
- 5-8卷：建议启用，有一定效果
- 3卷以下：不必要，原始方案已经够好

---

## 未来扩展方向

### 1. 两阶段生成

- **阶段1**：创建项目时，生成全书所有章节的简要大纲（20-30字/章）
- **阶段2**：用户点击某一卷时，扩展该卷的简要大纲为详细大纲（80-150字/章）

**优点**：
- AI有全局视角，逻辑一致性最强
- 按需扩展，节约token
- 可多次调整和优化

**实现难度**：中等，需要新增UI和工作流

### 2. 自动一致性检查

- 生成大纲后，自动调用`validateOutlineConsistency()`
- 在UI中显示冲突和建议
- 提供一键修复功能

**实现难度**：简单，函数已存在

### 3. 语义匹配升级

当前检测冲突使用简单的关键词匹配，可升级为：
- 使用Embedding模型计算语义相似度
- 更准确地检测内容重复和冲突

**实现难度**：高，需要额外API调用

### 4. 卷摘要自动更新

- 章节生成后，自动更新卷摘要
- 从生成的章节大纲中提取新的核心要点

**实现难度**：简单

---

## 总结

通过**分层大纲 + 智能压缩 + 一致性索引**三位一体的优化：

✅ **Token节约**：62.5%（单卷）→ 50%（全书含提取）
✅ **逻辑一致性**：卷边界清晰，全书视角完整
✅ **用户体验**：一键优化，自动压缩，无需手动调整
✅ **可扩展性**：预留验证、两阶段生成等扩展接口

这是百万巨著创作的重大升级！🎉
